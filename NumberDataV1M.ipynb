{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13H3QBZaZ-bzGt6cZTdvZKMJ1m8Bu3ePZ",
      "authorship_tag": "ABX9TyMvD5lFEchFNATfZpR77SIM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TrevorNgu/Number-Data-Model/blob/main/NumberDataV1M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"./drive/MyDrive/NumberData/10000VV\" -d \"/content\""
      ],
      "metadata": {
        "id": "qAPSH98i5XsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVp2QSu45WGp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88292751-63db-4463-c404-8ca5731ce157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n",
            "1. Create Model\n",
            "2. Load Model\n",
            "3. Save Model\n",
            "4. Train with Model\n",
            "5. Predict with Model\n",
            "6. Exit\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Failed to read source code from path: /content/<ipython-input-5-828d9bbd0bab>. Reason: Source path neither exists nor can be loaded as a .par file: /content/<ipython-input-5-828d9bbd0bab>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_None (Fun  (None, 1, 1, 1280)        2259136   \n",
            " ctional)                                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2271946 (8.67 MB)\n",
            "Trainable params: 2237834 (8.54 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "_________________________________________________________________\n",
            "1. Create Model\n",
            "2. Load Model\n",
            "3. Save Model\n",
            "4. Train with Model\n",
            "5. Predict with Model\n",
            "6. Exit\n",
            "4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:39<00:00, 250.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([False], shape=(1,), dtype=bool)\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "False\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_None (Fun  (None, 1, 1, 1280)        2259136   \n",
            " ctional)                                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2271946 (8.67 MB)\n",
            "Trainable params: 2237834 (8.54 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/80\n",
            "63/63 [==============================] - 132s 853ms/step - loss: 2.4799 - accuracy: 0.1391 - val_loss: 2.3027 - val_accuracy: 0.0960\n",
            "Epoch 2/80\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 2.0508 - accuracy: 0.2567 - val_loss: 2.3044 - val_accuracy: 0.1060\n",
            "Epoch 3/80\n",
            "63/63 [==============================] - 51s 795ms/step - loss: 1.8247 - accuracy: 0.3532 - val_loss: 2.3084 - val_accuracy: 0.0960\n",
            "Epoch 4/80\n",
            "63/63 [==============================] - 48s 753ms/step - loss: 1.6281 - accuracy: 0.4280 - val_loss: 2.3135 - val_accuracy: 0.0960\n",
            "Epoch 5/80\n",
            "63/63 [==============================] - 47s 747ms/step - loss: 1.5288 - accuracy: 0.4665 - val_loss: 2.3181 - val_accuracy: 0.0960\n",
            "Epoch 6/80\n",
            "63/63 [==============================] - 47s 742ms/step - loss: 1.3748 - accuracy: 0.5254 - val_loss: 2.3347 - val_accuracy: 0.1060\n",
            "Epoch 7/80\n",
            "63/63 [==============================] - 55s 876ms/step - loss: 1.2919 - accuracy: 0.5571 - val_loss: 2.3336 - val_accuracy: 0.1060\n",
            "Epoch 8/80\n",
            "63/63 [==============================] - 48s 769ms/step - loss: 1.2041 - accuracy: 0.5941 - val_loss: 2.3440 - val_accuracy: 0.1060\n",
            "Epoch 9/80\n",
            "63/63 [==============================] - 48s 760ms/step - loss: 1.1547 - accuracy: 0.6056 - val_loss: 2.3677 - val_accuracy: 0.1060\n",
            "Epoch 10/80\n",
            "63/63 [==============================] - 49s 782ms/step - loss: 1.0452 - accuracy: 0.6534 - val_loss: 2.3623 - val_accuracy: 0.0960\n",
            "Epoch 11/80\n",
            "63/63 [==============================] - 48s 767ms/step - loss: 1.0096 - accuracy: 0.6679 - val_loss: 2.3768 - val_accuracy: 0.1060\n",
            "Epoch 12/80\n",
            "63/63 [==============================] - 49s 774ms/step - loss: 0.9433 - accuracy: 0.6861 - val_loss: 2.3776 - val_accuracy: 0.1060\n",
            "Epoch 13/80\n",
            "63/63 [==============================] - 48s 766ms/step - loss: 0.9000 - accuracy: 0.6984 - val_loss: 2.3977 - val_accuracy: 0.1060\n",
            "Epoch 14/80\n",
            "63/63 [==============================] - 48s 760ms/step - loss: 0.8457 - accuracy: 0.7169 - val_loss: 2.4388 - val_accuracy: 0.1060\n",
            "Epoch 15/80\n",
            "63/63 [==============================] - 52s 829ms/step - loss: 0.7921 - accuracy: 0.7444 - val_loss: 2.4210 - val_accuracy: 0.1060\n",
            "Epoch 16/80\n",
            "63/63 [==============================] - 47s 756ms/step - loss: 0.7940 - accuracy: 0.7354 - val_loss: 2.4003 - val_accuracy: 0.1010\n",
            "Epoch 17/80\n",
            "63/63 [==============================] - 48s 771ms/step - loss: 0.7256 - accuracy: 0.7564 - val_loss: 2.4056 - val_accuracy: 0.1060\n",
            "Epoch 18/80\n",
            "63/63 [==============================] - 48s 762ms/step - loss: 0.6987 - accuracy: 0.7674 - val_loss: 2.4670 - val_accuracy: 0.0960\n",
            "Epoch 19/80\n",
            "63/63 [==============================] - 48s 765ms/step - loss: 0.6503 - accuracy: 0.7866 - val_loss: 2.4455 - val_accuracy: 0.0960\n",
            "Epoch 20/80\n",
            "63/63 [==============================] - 48s 771ms/step - loss: 0.6296 - accuracy: 0.7945 - val_loss: 2.4196 - val_accuracy: 0.0960\n",
            "Epoch 21/80\n",
            "63/63 [==============================] - 48s 765ms/step - loss: 0.5966 - accuracy: 0.8034 - val_loss: 2.4340 - val_accuracy: 0.0960\n",
            "Epoch 22/80\n",
            "63/63 [==============================] - 49s 774ms/step - loss: 0.5885 - accuracy: 0.8050 - val_loss: 2.4510 - val_accuracy: 0.1060\n",
            "Epoch 23/80\n",
            "63/63 [==============================] - 49s 777ms/step - loss: 0.5504 - accuracy: 0.8161 - val_loss: 2.4610 - val_accuracy: 0.1060\n",
            "Epoch 24/80\n",
            "63/63 [==============================] - 47s 755ms/step - loss: 0.5659 - accuracy: 0.8158 - val_loss: 2.4753 - val_accuracy: 0.1060\n",
            "Epoch 25/80\n",
            "63/63 [==============================] - 48s 765ms/step - loss: 0.6619 - accuracy: 0.7893 - val_loss: 2.4500 - val_accuracy: 0.1060\n",
            "Epoch 26/80\n",
            "63/63 [==============================] - 48s 770ms/step - loss: 0.5615 - accuracy: 0.8194 - val_loss: 2.4710 - val_accuracy: 0.1060\n",
            "Epoch 27/80\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.5036 - accuracy: 0.8376 - val_loss: 2.4495 - val_accuracy: 0.1060\n",
            "Epoch 28/80\n",
            "63/63 [==============================] - 52s 834ms/step - loss: 0.4603 - accuracy: 0.8505 - val_loss: 2.4597 - val_accuracy: 0.1060\n",
            "Epoch 29/80\n",
            "63/63 [==============================] - 49s 775ms/step - loss: 0.4318 - accuracy: 0.8599 - val_loss: 2.4776 - val_accuracy: 0.1010\n",
            "Epoch 30/80\n",
            "63/63 [==============================] - 48s 759ms/step - loss: 0.4274 - accuracy: 0.8595 - val_loss: 2.4655 - val_accuracy: 0.1060\n",
            "Epoch 31/80\n",
            "63/63 [==============================] - 54s 867ms/step - loss: 0.4183 - accuracy: 0.8629 - val_loss: 2.4564 - val_accuracy: 0.1060\n",
            "Epoch 32/80\n",
            "63/63 [==============================] - 50s 788ms/step - loss: 0.4067 - accuracy: 0.8644 - val_loss: 2.4756 - val_accuracy: 0.1060\n",
            "Epoch 33/80\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.3918 - accuracy: 0.8680 - val_loss: 2.5145 - val_accuracy: 0.1060\n",
            "Epoch 34/80\n",
            "63/63 [==============================] - 51s 808ms/step - loss: 0.3753 - accuracy: 0.8765 - val_loss: 2.4810 - val_accuracy: 0.1060\n",
            "Epoch 35/80\n",
            "63/63 [==============================] - 48s 766ms/step - loss: 0.3540 - accuracy: 0.8842 - val_loss: 2.5120 - val_accuracy: 0.1060\n",
            "Epoch 36/80\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 0.3857 - accuracy: 0.8737 - val_loss: 2.4821 - val_accuracy: 0.1060\n",
            "Epoch 37/80\n",
            "63/63 [==============================] - 50s 794ms/step - loss: 0.3291 - accuracy: 0.8959 - val_loss: 2.4534 - val_accuracy: 0.1055\n",
            "Epoch 38/80\n",
            "63/63 [==============================] - 48s 757ms/step - loss: 0.3574 - accuracy: 0.8823 - val_loss: 2.4877 - val_accuracy: 0.1060\n",
            "Epoch 39/80\n",
            "63/63 [==============================] - 47s 750ms/step - loss: 0.3340 - accuracy: 0.8871 - val_loss: 2.5343 - val_accuracy: 0.1060\n",
            "Epoch 40/80\n",
            "63/63 [==============================] - 55s 870ms/step - loss: 0.3312 - accuracy: 0.8896 - val_loss: 2.5381 - val_accuracy: 0.1060\n",
            "Epoch 41/80\n",
            "63/63 [==============================] - 48s 758ms/step - loss: 0.3051 - accuracy: 0.8990 - val_loss: 2.5087 - val_accuracy: 0.1060\n",
            "Epoch 42/80\n",
            "63/63 [==============================] - 48s 758ms/step - loss: 0.3316 - accuracy: 0.8936 - val_loss: 2.4929 - val_accuracy: 0.1060\n",
            "Epoch 43/80\n",
            "63/63 [==============================] - 49s 774ms/step - loss: 0.2992 - accuracy: 0.9013 - val_loss: 2.5694 - val_accuracy: 0.1060\n",
            "Epoch 44/80\n",
            "63/63 [==============================] - 47s 747ms/step - loss: 0.2898 - accuracy: 0.9056 - val_loss: 2.5095 - val_accuracy: 0.1055\n",
            "Epoch 45/80\n",
            "63/63 [==============================] - 48s 761ms/step - loss: 0.2830 - accuracy: 0.9086 - val_loss: 2.6080 - val_accuracy: 0.1055\n",
            "Epoch 46/80\n",
            "63/63 [==============================] - 50s 802ms/step - loss: 0.2542 - accuracy: 0.9150 - val_loss: 2.5500 - val_accuracy: 0.1055\n",
            "Epoch 47/80\n",
            "63/63 [==============================] - 47s 747ms/step - loss: 0.2902 - accuracy: 0.9085 - val_loss: 2.5399 - val_accuracy: 0.1060\n",
            "Epoch 48/80\n",
            "63/63 [==============================] - 48s 764ms/step - loss: 0.2323 - accuracy: 0.9241 - val_loss: 2.5525 - val_accuracy: 0.1060\n",
            "Epoch 49/80\n",
            "63/63 [==============================] - 50s 805ms/step - loss: 0.2591 - accuracy: 0.9139 - val_loss: 2.5378 - val_accuracy: 0.1055\n",
            "Epoch 50/80\n",
            "63/63 [==============================] - 47s 751ms/step - loss: 0.2795 - accuracy: 0.9059 - val_loss: 2.5606 - val_accuracy: 0.1060\n",
            "Epoch 51/80\n",
            "63/63 [==============================] - 48s 765ms/step - loss: 0.2512 - accuracy: 0.9154 - val_loss: 2.5076 - val_accuracy: 0.1055\n",
            "Epoch 52/80\n",
            "63/63 [==============================] - 58s 929ms/step - loss: 0.2144 - accuracy: 0.9305 - val_loss: 2.4926 - val_accuracy: 0.1055\n",
            "Epoch 53/80\n",
            "63/63 [==============================] - 48s 767ms/step - loss: 0.2149 - accuracy: 0.9275 - val_loss: 2.5071 - val_accuracy: 0.1055\n",
            "Epoch 54/80\n",
            "63/63 [==============================] - 47s 752ms/step - loss: 0.2186 - accuracy: 0.9281 - val_loss: 2.5769 - val_accuracy: 0.1055\n",
            "Epoch 55/80\n",
            "63/63 [==============================] - 50s 802ms/step - loss: 0.2331 - accuracy: 0.9197 - val_loss: 2.5641 - val_accuracy: 0.1060\n",
            "Epoch 56/80\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 0.1882 - accuracy: 0.9356 - val_loss: 2.5872 - val_accuracy: 0.1055\n",
            "Epoch 57/80\n",
            "63/63 [==============================] - 48s 766ms/step - loss: 0.2011 - accuracy: 0.9336 - val_loss: 2.6424 - val_accuracy: 0.1055\n",
            "Epoch 58/80\n",
            "63/63 [==============================] - 52s 826ms/step - loss: 0.2194 - accuracy: 0.9280 - val_loss: 2.5669 - val_accuracy: 0.1055\n",
            "Epoch 59/80\n",
            "63/63 [==============================] - 48s 760ms/step - loss: 0.2290 - accuracy: 0.9246 - val_loss: 2.6311 - val_accuracy: 0.1055\n",
            "Epoch 60/80\n",
            "63/63 [==============================] - 47s 744ms/step - loss: 0.2356 - accuracy: 0.9211 - val_loss: 2.6365 - val_accuracy: 0.1055\n",
            "Epoch 61/80\n",
            "63/63 [==============================] - 50s 799ms/step - loss: 0.2068 - accuracy: 0.9320 - val_loss: 2.6308 - val_accuracy: 0.1055\n",
            "Epoch 62/80\n",
            "63/63 [==============================] - 49s 777ms/step - loss: 0.1523 - accuracy: 0.9461 - val_loss: 2.5834 - val_accuracy: 0.1060\n",
            "Epoch 63/80\n",
            "63/63 [==============================] - 46s 740ms/step - loss: 0.1813 - accuracy: 0.9409 - val_loss: 2.6860 - val_accuracy: 0.1060\n",
            "Epoch 64/80\n",
            "63/63 [==============================] - 50s 794ms/step - loss: 0.1960 - accuracy: 0.9319 - val_loss: 2.6201 - val_accuracy: 0.1055\n",
            "Epoch 65/80\n",
            "63/63 [==============================] - 54s 856ms/step - loss: 0.1685 - accuracy: 0.9442 - val_loss: 2.5907 - val_accuracy: 0.1055\n",
            "Epoch 66/80\n",
            "63/63 [==============================] - 48s 771ms/step - loss: 0.1887 - accuracy: 0.9380 - val_loss: 2.5765 - val_accuracy: 0.1060\n",
            "Epoch 67/80\n",
            "63/63 [==============================] - 50s 804ms/step - loss: 0.1751 - accuracy: 0.9435 - val_loss: 2.6227 - val_accuracy: 0.1055\n",
            "Epoch 68/80\n",
            "63/63 [==============================] - 47s 747ms/step - loss: 0.1905 - accuracy: 0.9375 - val_loss: 2.6715 - val_accuracy: 0.0930\n",
            "Epoch 69/80\n",
            "63/63 [==============================] - 49s 788ms/step - loss: 0.1993 - accuracy: 0.9336 - val_loss: 2.5540 - val_accuracy: 0.0930\n",
            "Epoch 70/80\n",
            "63/63 [==============================] - 51s 809ms/step - loss: 0.1797 - accuracy: 0.9424 - val_loss: 2.6319 - val_accuracy: 0.0930\n",
            "Epoch 71/80\n",
            "63/63 [==============================] - 50s 792ms/step - loss: 0.1775 - accuracy: 0.9410 - val_loss: 2.5569 - val_accuracy: 0.0930\n",
            "Epoch 72/80\n",
            "63/63 [==============================] - 48s 759ms/step - loss: 0.1905 - accuracy: 0.9364 - val_loss: 2.5879 - val_accuracy: 0.0930\n",
            "Epoch 73/80\n",
            "63/63 [==============================] - 52s 834ms/step - loss: 0.1754 - accuracy: 0.9420 - val_loss: 2.6059 - val_accuracy: 0.0930\n",
            "Epoch 74/80\n",
            "63/63 [==============================] - 48s 763ms/step - loss: 0.1549 - accuracy: 0.9477 - val_loss: 2.6825 - val_accuracy: 0.0930\n",
            "Epoch 75/80\n",
            "63/63 [==============================] - 48s 759ms/step - loss: 0.1503 - accuracy: 0.9506 - val_loss: 2.9053 - val_accuracy: 0.0930\n",
            "Epoch 76/80\n",
            "63/63 [==============================] - 49s 788ms/step - loss: 0.1274 - accuracy: 0.9564 - val_loss: 2.9094 - val_accuracy: 0.0930\n",
            "Epoch 77/80\n",
            "63/63 [==============================] - 52s 833ms/step - loss: 0.1627 - accuracy: 0.9461 - val_loss: 2.7809 - val_accuracy: 0.1120\n",
            "Epoch 78/80\n",
            "63/63 [==============================] - 47s 750ms/step - loss: 0.1343 - accuracy: 0.9526 - val_loss: 2.9616 - val_accuracy: 0.0930\n",
            "Epoch 79/80\n",
            "63/63 [==============================] - 47s 751ms/step - loss: 0.1472 - accuracy: 0.9520 - val_loss: 3.0789 - val_accuracy: 0.0930\n",
            "Epoch 80/80\n",
            "63/63 [==============================] - 46s 733ms/step - loss: 0.1308 - accuracy: 0.9604 - val_loss: 3.1172 - val_accuracy: 0.0950\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_None (Fun  (None, 1, 1, 1280)        2259136   \n",
            " ctional)                                                        \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2271946 (8.67 MB)\n",
            "Trainable params: 2237834 (8.54 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "_________________________________________________________________\n",
            "1. Create Model\n",
            "2. Load Model\n",
            "3. Save Model\n",
            "4. Train with Model\n",
            "5. Predict with Model\n",
            "6. Exit\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf;\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import PIL\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import decode_predictions\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.applications import resnet50\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras import Model\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "tf.debugging.experimental.enable_dump_debug_info(\n",
        "    \"/tmp/tfdbg2_logdir\",\n",
        "    tensor_debug_mode=\"FULL_HEALTH\",\n",
        "    circular_buffer_size=-1)\n",
        "\n",
        "curr_model = None\n",
        "\n",
        "def read_7_bytes(file):\n",
        "  \"\"\"Reads 7 bytes from a file and returns them as a NumPy array.\"\"\"\n",
        "  bytes = file.read(7)\n",
        "  if len(bytes) < 7:\n",
        "    return None\n",
        "  return np.frombuffer(bytes, dtype=np.uint8)\n",
        "\n",
        "def read_dir():\n",
        "  path = \"./train/\"\n",
        "  comb_arr = []\n",
        "  for dire in os.listdir(path):\n",
        "    fpath = os.path.join(path, dire)\n",
        "    file = open(fpath, \"rb\")\n",
        "\n",
        "    header = file.readline().decode(\"utf-8\").strip()\n",
        "    width = file.readline().decode(\"utf-8\").strip()\n",
        "    height = file.readline().decode(\"utf-8\").strip()\n",
        "    bitsperfilter = file.readline().decode(\"utf-8\").strip()\n",
        "    diameter = file.readline().decode(\"utf-8\").strip()\n",
        "    vertspace = file.readline().decode(\"utf-8\").strip()\n",
        "    horspace = file.readline().decode(\"utf-8\").strip()\n",
        "    horfirst = file.readline().decode(\"utf-8\").strip()\n",
        "    vertfirst = file.readline().decode(\"utf-8\").strip()\n",
        "\n",
        "    #print(header + \" \" + width + \" \" + height + \" \" + bitsperfilter + \" \" + diameter + \" \" + vertspace + \" \" + horspace + \" \" + horfirst + \" \" + vertfirst)\n",
        "\n",
        "    array = np.array([])\n",
        "    array.setflags(write=1)\n",
        "    i = 0\n",
        "    while True:\n",
        "      i += 1\n",
        "      bytes = read_7_bytes(file)\n",
        "      bytes = np.copy(bytes)\n",
        "\n",
        "      if bytes.all() == None:\n",
        "        print(i)\n",
        "        break\n",
        "\n",
        "      bytes = bytes/255\n",
        "      print(bytes)\n",
        "      #for i in range(7):\n",
        "        #bytes[i] = (bytes[i] - 128)\n",
        "        #bytes[i] = (bytes[i] * 23000)\n",
        "\n",
        "      #print(bytes)\n",
        "      array = np.append(array, bytes)\n",
        "\n",
        "    array = array.reshape(11, 9, 7)\n",
        "    #print(array.shape)\n",
        "    comb_arr.append(array)\n",
        "    #val = array.reshape(11, 9, 7)\n",
        "    #val = tf.convert_to_tensor(array, dtype=\"float32\")\n",
        "    #print(\"dir read\")\n",
        "  val = np.array(comb_arr)\n",
        "  print(val.shape)\n",
        "    #return val\n",
        "\n",
        "def image_files(input_directory):\n",
        "    filepaths=[]\n",
        "    labels=[]\n",
        "\n",
        "    digit_folders=os.listdir(input_directory)\n",
        "    #print(digit_folders)\n",
        "\n",
        "    for digit in digit_folders:\n",
        "        path=os.path.join(input_directory, digit)\n",
        "        flist=os.listdir(path)\n",
        "        for f in flist:\n",
        "            fpath=os.path.join(path,f)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(digit)\n",
        "    return filepaths,labels\n",
        "\n",
        "def load_images(filepaths):\n",
        "    images = []\n",
        "    for i in tqdm(range(len(filepaths))):\n",
        "        img = None\n",
        "        file = open(filepaths[i], \"rb\")\n",
        "        if filepaths[i][-3:] != 'v1m':\n",
        "          continue\n",
        "        header = file.readline().decode(\"utf-8\").strip()\n",
        "        width = file.readline().decode(\"utf-8\").strip()\n",
        "        height = file.readline().decode(\"utf-8\").strip()\n",
        "        bitsperfilter = file.readline().decode(\"utf-8\").strip()\n",
        "        diameter = file.readline().decode(\"utf-8\").strip()\n",
        "        vertspace = file.readline().decode(\"utf-8\").strip()\n",
        "        horspace = file.readline().decode(\"utf-8\").strip()\n",
        "        horfirst = file.readline().decode(\"utf-8\").strip()\n",
        "        vertfirst = file.readline().decode(\"utf-8\").strip()\n",
        "\n",
        "        #print(header + \" \" + width + \" \" + height + \" \" + bitsperfilter + \" \" + diameter + \" \" + vertspace + \" \" + horspace + \" \" + horfirst + \" \" + vertfirst)\n",
        "\n",
        "        array = np.array([])\n",
        "        array.setflags(write=1)\n",
        "        i = 0\n",
        "        while True:\n",
        "          i += 1\n",
        "          bytes = read_7_bytes(file)\n",
        "          bytes = np.copy(bytes)\n",
        "\n",
        "          if bytes.all() == None:\n",
        "            #print(i)\n",
        "            break\n",
        "\n",
        "          bytes = bytes/255\n",
        "          if np.any(bytes <= 0) or np.any(bytes >= 1):\n",
        "            print(\"found\")\n",
        "\n",
        "          #print(bytes)\n",
        "          #for i in range(7):\n",
        "            #bytes[i] = (bytes[i] - 128)\n",
        "            #bytes[i] = (bytes[i] * 23000)\n",
        "\n",
        "          #print(bytes)\n",
        "          array = np.append(array, bytes)\n",
        "\n",
        "        array = array.reshape(11, 9, 7)\n",
        "        #img = image.load_img(filepaths[i], target_size=(32,32,3))\n",
        "        #img = image.img_to_array(img)\n",
        "        #img.astype('float32')\n",
        "        #img = img/255\n",
        "        images.append(array)\n",
        "\n",
        "    images = np.array(images)\n",
        "    return images\n",
        "\n",
        "def createModel():\n",
        "  global curr_model\n",
        "  input_s = layers.Input((11,9,7))\n",
        "  model_arch = tf.keras.applications.MobileNetV2(\n",
        "  input_tensor=input_s,\n",
        "  include_top=False,\n",
        "  weights=None)\n",
        "\n",
        "  curr_model = Sequential()\n",
        "  curr_model.add(model_arch)\n",
        "  curr_model.add(Flatten())\n",
        "  curr_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  curr_model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  curr_model.summary()\n",
        "\n",
        "def loadModel():\n",
        "  global curr_model\n",
        "  curr_model = tf.keras.models.load_model('./drive/MyDrive/NumberData/model/my_model.h5')\n",
        "  curr_model.summary()\n",
        "\n",
        "def saveModel():\n",
        "  global curr_model\n",
        "  if curr_model == None:\n",
        "    print(\"No model currently\")\n",
        "  else:\n",
        "    print()\n",
        "    #curr_model.save('./drive/MyDrive/NumberData/model')\n",
        "\n",
        "def trainModel():\n",
        "  directory = \"./10000VV\"\n",
        "  filepaths, labels = image_files(directory)\n",
        "\n",
        "  images = load_images(filepaths)\n",
        "  x = tf.math.is_inf(images)\n",
        "  flattened_tensor = tf.reshape(x, [-1])\n",
        "\n",
        "  # Find the unique values\n",
        "  unique_values, indices = tf.unique(flattened_tensor)\n",
        "\n",
        "  # Print the unique values\n",
        "  print(unique_values)\n",
        "  y = to_categorical(labels, num_classes=10)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(images, y, random_state=42, test_size=0.2)\n",
        "\n",
        "  print(np.any(np.isnan(x_train)))\n",
        "  print(np.any(np.isnan(y_train)))\n",
        "  print(np.any(np.isnan(x_test)))\n",
        "  print(np.any(np.isnan(y_test)))\n",
        "\n",
        "  print(np.any(np.isinf(x_train)))\n",
        "  print(np.any(np.isinf(y_train)))\n",
        "  print(np.any(np.isinf(x_test)))\n",
        "  print(np.any(np.isinf(y_test)))\n",
        "\n",
        "  print(np.any(np.isfinite(x_train)))\n",
        "  print(np.any(np.isfinite(y_train)))\n",
        "  print(np.any(np.isfinite(x_test)))\n",
        "  print(np.any(np.isfinite(y_test)))\n",
        "\n",
        "  print(np.any(x_train >= 1))\n",
        "  print(np.any(x_train <= 0))\n",
        "  print(np.any(y_train >= 11))\n",
        "  print(np.any(y_train <= -1))\n",
        "  print(np.any(x_test >= 1))\n",
        "  print(np.any(x_test <= 0))\n",
        "  print(np.any(y_test >= 11))\n",
        "  print(np.any(y_test <= -1))\n",
        "\n",
        "\n",
        "  curr_model.summary()\n",
        "\n",
        "  history = curr_model.fit(x_train, y_train,\n",
        "                           epochs=80,\n",
        "                           batch_size=128,\n",
        "                           validation_data=(x_test, y_test))\n",
        "  curr_model.summary()\n",
        "\n",
        "  curr_model.save('./drive/MyDrive/NumberData/model/my_model.h5')\n",
        "\n",
        "def predict():\n",
        "  global curr_model\n",
        "  pathy = 'predict/'\n",
        "  fname = input()\n",
        "  pathy = pathy + fname\n",
        "  file = open(pathy, \"rb\")\n",
        "\n",
        "  header = file.readline().decode(\"utf-8\").strip()\n",
        "  width = file.readline().decode(\"utf-8\").strip()\n",
        "  height = file.readline().decode(\"utf-8\").strip()\n",
        "  bitsperfilter = file.readline().decode(\"utf-8\").strip()\n",
        "  diameter = file.readline().decode(\"utf-8\").strip()\n",
        "  vertspace = file.readline().decode(\"utf-8\").strip()\n",
        "  horspace = file.readline().decode(\"utf-8\").strip()\n",
        "  horfirst = file.readline().decode(\"utf-8\").strip()\n",
        "  vertfirst = file.readline().decode(\"utf-8\").strip()\n",
        "\n",
        "  #print(header + \" \" + width + \" \" + height + \" \" + bitsperfilter + \" \" + diameter + \" \" + vertspace + \" \" + horspace + \" \" + horfirst + \" \" + vertfirst)\n",
        "\n",
        "  array = np.array([])\n",
        "  array.setflags(write=1)\n",
        "  i = 0\n",
        "  while True:\n",
        "    i += 1\n",
        "    bytes = read_7_bytes(file)\n",
        "    bytes = np.copy(bytes)\n",
        "\n",
        "    if bytes.all() == None:\n",
        "      print(i)\n",
        "      break\n",
        "\n",
        "    bytes = bytes/255\n",
        "    print(bytes)\n",
        "    #for i in range(7):\n",
        "      #bytes[i] = (bytes[i] - 128)\n",
        "      #bytes[i] = (bytes[i] * 23000)\n",
        "\n",
        "    #print(bytes)\n",
        "    array = np.append(array, bytes)\n",
        "\n",
        "  array = array.reshape(-1, 11, 9, 7)\n",
        "  print(array.shape)\n",
        "\n",
        "  prediction = curr_model.predict(array)\n",
        "  print(prediction)\n",
        "\n",
        "while True:\n",
        "  print(\"1. Create Model\\n2. Load Model\\n3. Save Model\\n4. Train with Model\\n5. Predict with Model\\n6. Exit\")\n",
        "  x = int(input())\n",
        "\n",
        "  match x:\n",
        "    case 1:\n",
        "        createModel()\n",
        "    case 2:\n",
        "        loadModel()\n",
        "    case 3:\n",
        "        saveModel()\n",
        "    case 4:\n",
        "        trainModel()\n",
        "    case 5:\n",
        "        predict()\n",
        "    case 6:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /tmp/tfdbg2_logdir"
      ],
      "metadata": {
        "id": "IDbsVoaJofmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "llM7uwo-wh2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}